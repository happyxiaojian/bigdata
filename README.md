# BIGDATA
**the proof of work of the bigdata learning**

“没时间了”，是“时间恐慌症”患者脑子里唯一反复闪现的一句话。巨大的压力，极度的恐慌，使“患者”身上综合了一切矛盾：他们既勤奋又懒惰，既聪明又愚蠢，既勇敢又懦弱，既满怀希望又分分秒秒面临绝望，既充满自信又随时随地体会自卑……

“没时间了”，其可怕程度几乎无异于死亡。死亡是所有人都要面临的终极困境——没有解决方案的困境。对其恐惧之甚，以至人类不分种群，不约而同地集体创造出一个天堂留给自己和自己喜爱的同类，同时还创造出一个地狱送给自己憎恨的同类。但这毕竟不是切实有效的解决方案。死亡本身其实并不可怕，面临死亡的过程才真正可怕。如此，就能很容易地体会那些“既勤奋又懒惰”的学生，面临的是怎样的悲惨境遇了。

但是，生活中明显有另外一些人——尽管数量上并不占优——在用另外一种状态生活。他们从容，他们优雅，他们善于化解各种压力，安静地去做他们认为应该做的事情，并总能有所成就。他们甚至可以达到常人无法想象的境界——不以物喜，不以己悲。面对同样的困境，这另外的一些人究竟是如何保持从容的呢？

这是我第一次意识到“有些认识，哪怕是简单的常识，也需要亲身经历后才能真正体会”。只有拥有无与伦比的打字速度，才能体会打字速度快的好处。

> > 心智真正成熟的人在一些情况下能够做到无须亲自经历，仅凭思考就得到深刻的体会。

打字速度提升后，我发现自己不再讨厌在读书的时候做笔记了，因为在键盘上敲字相对于纸和笔来说轻松太多。我开始大段地记录感想，有时甚至干脆整篇摘抄原文！真正体会到读书时做笔记、甚至大量地做笔记究竟有多大好处后，我突然明白自己过去拒绝学习盲打的想法是多么荒谬。而当时，就算没有异性的刺激，盲打也是顶多只花一星期就可以搞定的事情，我竟然仅仅由于懒惰便拒绝了。如果，哪怕5年前，我花上一个星期学会盲打，那么，我可以多写多少读书笔记、积累多少文字呢？更何况，10多年前，我就有机会、并且完全可能学会盲打。**天哪，我浪费了多少时间！**



### #2019年4月2日 10:02:38

昨天弄到凌晨2点, 也是因为环境的问题, 每次都在环境的问题上花费很多的时间. 

每天的学习的时间从22:00 到 01:00 三个小时的时间, 理想的情况下按2倍速来看的话,应该可以看6个视频左右, 但一直达不到这个状态, 3个小时也就看三个小时左右的视频, 而且能记住的东西很少.

今天的任务: 把昨天没有完成的部分尽量完成 

- [ ] 2 生态架构课--04 Hbase  4h    --- > 50%
- [ ] 2 生态架构课--05 Hive      4h    ----> 0%

### #2019年4月1日 09:52:25

昨天没有写日记,但前天看的是 storm 的内容, 忘的差不多了. 

昨天早上10点到公司晚上凌晨1点离开, 在公司呆了16个小时,成果就是看了spark的内容.

有一个重要的发现就是以前的视频还是要看的,因为课上讲的知识点都是以看了预习的视频为基础扩展开来讲的,其实他上课讲的内容量是很小的,但他是兼职的抽不出更多的时间,所以要自己看看预习的视频.

还发现了,视频看一遍根本就没感觉基本全部忘光了,至少看3遍以上,还有结合文字笔记来看,有可能的话,自己根据查资料整理出笔记出来.看第二遍的时候才能记得一点内容.至少看三遍以上.慢慢来,急也没有用.

> 【No.12】Yarn+HDFS
>
> 【No.13、14】Yarn+Spark

今天的任务是:

- [ ] 2 生态架构课--04 Hbase  4h    --- > 只完成了一半
- [ ] 2 生态架构课--05 Hive      4h    ----> 没开始

HBASE 行锁 

**HMaster(主)**

1. 负载均衡:管理和分配HRegion
2. DDL: 增删改 -> table, cf, namespace
3. 类似namenode, 管理一些员数据, table
4. ACL权限控制

HRegionServer(从):

1. 管理和存放本地的HRegion

2. 读写HDFS, 提供IO操作

3. 本地化:HRegion的数据尽量和数据所属的DataNode在一块, 但是这个本地化不能

    

### #2019年3月30日 09:24:01

昨天偷懒去打了羽毛球，然后回家洗澡还洗了衣服。磨磨蹭蹭到了12点钟，时间真是一不小心就偷偷的过去了，学习的进度依然很慢，一个星期了才实践了zookeeper这一节的内容。本来他讲课的内容就是很少的，现在自己居然快放都跟不上他的进度。还发现了一个问题就是，无法量化在自己的进度和学习的情况，不知道学到什么程度才能达到自己的薪资目标。我的潜力到底在哪里。我学习为什么不能像别人一样有效果，至少在薪资上体现出自己的价值出来。

> 学习 【No.22、23】Storm+zookeeper   这以节的内容，而且只学习了zookeeper部分

积累根本不是时间的堆砌而是真正的身心和时间的投入。

今天的任务是：把slave1 和 slave2 上的 zkpython 的运行环境搭起来。

2019年3月30日 15:25:36 环境已经搭好了，发现一个规律：就是在发现问题的刚开始的阶段，很难找到好的问题的解决方案，感觉自己的问题是独一无二，但是慢慢的只要自己的不停的去找问题原因，后来发现各种解决方案都冒了出来，实在是很奇怪的现象，我的分析如下：在问题的起始阶段，一个问题往往带着另外一个问题，随着外围的问题慢慢的解决，原始的问题才能很好的解决，环境的问题一环扣着一环。问题的连环套。

### #2019年3月29日 10:12:58

昨天晚上弄环境弄到差不多2点多钟，最后解决的时候发现是非常愚蠢的错误。在启动zookeeper 的时候在master上 ssh 到slave1 然后当成是master主机，不断的去修改 myid ，同时也在slave1上修改myid, master的id 是1， slave1的id 是3，然后不断的来回的修改，还以为有什么进程在修改这个数据；另外，应该是master 和slave 的同时开启后，查看 zkServer.sh status 才不会报错。这个愚蠢的错误花了我大概4个小时；还发现一个问题是，以前为了求快，在解决问题的过程直接把解决问题的网页的链接保存了下来，但是解决问题的逻辑却忘记了。给自己的解决方案是，记录下自己的问题和解决问题的过程。这样在问题下次出现的时候就可以有依据可以查询。现在的情况是，slave1 和 slave2 在安装zkpython的时候要重新开始。本来在master上已经安装好了。

在linux运行环境上花的时间过多。



### #2019年3月28日 10:41:30

人在学习新的东西的时候内心都是很抵触的，一定要意识到这一点，并与之对抗，慢慢的将这种不好的感觉用解决之后的快感代替。

不管是只是还是工具，只会越用越熟练。

现在很多时间都浪费在环境的问题上，运行程序的时候，环境经常出现问题，排错的过程是很花时间的。不知道怎么解决，花的时间长，很让人沮丧。

昨天把 windows 下的 java 环境搭建起来，开始学习熟悉java和python的，目标是：

1. 可以看懂别人的程序
2. 可以手写常见的数据结构

现在在复习 HDFS ,不断的去理解概念 ，如果理解不了就死记下来。



### #2019年3月27日 09:44:39

今天看的一句比较有感觉的话是：所谓的成熟，有一个标志是喜欢的依旧喜欢但可以不拥有，害怕的依然害怕但可以去面对。

大数据学习的进度报告：昨天跟张盼聊天聊得忘了时间，几乎没怎么推进。昨天开始看python相关的东西了。在学习的过程中发现又一个问题是，以前的预习的东西有的缺少实践的环节。现在的策略是直接看正式课的内容，理论先过一遍，不纠结，然后实践，最后反过来验证理论，理解。

通过学习数据结构和算法去学习语言。数据结构和算法是通用的。

以后再每天的日志中加入每天新学到的概念的列表：

今天所学：

HBase 的列式存储就是根据 **CF** 分开存储（每个 **CF** 对应一个 **Store**）

**HBase** \  **行键RowKey**  \ **ColumnFamily**列族 \ 列成员**columnQualifier**    

时间戳**TimeStamp**  \  单元格**Cell**  \ 区域**Region** \ 



### #2019年3月26日 09:11:33

昨天通过 **PDF** 文档学习了**storm** 和 **zookeeper** , 学习的效果不尽人意，速度太慢，东西太多了看的多，马上就忘了。今天想到的是，可以多个文档一起比较起来看；另一个想到的学习的方式是，先把理论快速的过一遍，不对自己有过高的要求，不急于求成，然后马上进行理论的实践，通过实践再回过头去好好研究理论，这样应该可以避免空洞的看理论速度慢的问题。



### #2019年3月25日 09:06:30

昨天学习发现一个问题，学习的进度太慢了，以前一直喜欢看视频学习，分析了下那些内容比较简单的
东西很好理解；但是现在学习的东西很多都是非常复杂的，不容易理解，需要常常去复习，这
个时候视频就显得很鸡肋，还是文档容易复习，而且现在要慢慢的适应文档的自学方式.现在给每天的任
务是早上早读的方式去读文档。



### #2019年3月24日 22:00:33

看了9个小时的电视剧，19版的《倚天屠龙记》+ 《都挺好》
没有学习大数据，心情比较崩溃😫



### #2019-03-24 10:41:01

今天从9：30过来，到现在已经差不多学习一个小时，**HDFS**

**hadoop2.0** 的主要思想是**JobTracker**两个主要的功能分分离成单独的组件，这两个功
能是资源管理和任务调度/监控

新的资源管理器全局管理所有应用程序计算资源的分配

**ApplicationMaster**负责相应的调度和协调

**ResourceManager**和每一台机器的阶段管理服务器能够管理用户在哪台机器上的进程
并能对计算进行组织。

**NodeManager**是每一台机器框架的代理，是执行应用程序的容器，监控应用程序的资
源使用情况（CPU 内存 磁盘 网络）并且向调度器汇报。

每一个应用的**ApplicationMaster**的职责有：向调度器索要适当的资源容器，运行任务，
跟踪应用程序的状态和监控他们的进程，处理任务的失败原因

客户端不变，其调用API及接口大部分保持兼容，这也是为了开发使用者透明化，
对原码不必做大的改变，但是原框架的**JobTracker**和**TaskTracker**不见了，取而代之的
是ResourceManager AppliactionMaster NodeManager三个部分。

ResourceManager是一个中心的服务，它做的事情是调度、启动每一个Job所属的
ApplicationMaster、另外监控ApplicationMaster的存在情况。Job里面所在的task的监
控，重启等内容不见了，这就是ApplicationMaster存在的原因。ResourceManager负
责作业与资源的调度，接收JobSubmitter提交的作业，按照作业的上下文(context)信
息，以及从NodeManager收集来的状态信息，启动调度过程，分配一个Container作
为Application Master

 *NodeManager 功能比较专一，就是负责Container状态的维护，并向RM保持心跳。

ApplicationMaster负责一个Job生命周期内的所有工作，类似老的框架中JobTracker,
但注意每一个Job(不是每一种)都有一个ApplicationMaster,他可以运行在ResourceManager
以外的机器上.



### #2019-03-22 14:16:32

the second time edit README.MD





